"""
FiscalAI MVP - Testes de Performance
Testes automatizados para validar m√©tricas de performance
"""

import unittest
import time
import sys
import os
from pathlib import Path
from typing import Dict, List, Any
import json

# Adicionar src ao path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from src.utils.model_manager import get_model_manager
from src.agents import Agente1Extrator, Agente2Classificador, Agente3Validador, Agente5Interface
from src.detectors import OrquestradorDeteccaoFraudes
from src.models import NFe, ItemNFe
from src.utils.validation_dataset import ValidationDataset
from src.utils.metrics_dashboard import MetricsDashboard


class PerformanceTestSuite(unittest.TestCase):
    """
    Suite de testes de performance
    """
    
    @classmethod
    def setUpClass(cls):
        """Configura√ß√£o inicial para todos os testes"""
        print("üöÄ Iniciando Testes de Performance...")
        
        # Inicializar componentes
        cls.model_manager = get_model_manager()
        cls.llm = cls.model_manager.get_llm('mistral-7b-gguf')
        
        # Criar agentes
        cls.agente1 = Agente1Extrator(cls.llm)
        cls.agente2 = Agente2Classificador(cls.llm)
        cls.agente3 = Agente3Validador(cls.llm)
        cls.agente5 = Agente5Interface(cls.llm)
        
        # Criar orquestrador
        cls.orquestrador = OrquestradorDeteccaoFraudes()
        
        # Dataset de valida√ß√£o
        cls.validation_dataset = ValidationDataset()
        
        # Dashboard de m√©tricas
        cls.metrics_dashboard = MetricsDashboard()
        
        print("‚úÖ Componentes inicializados com sucesso!")
    
    def test_model_loading_time(self):
        """Testa tempo de carregamento do modelo"""
        print("\nü§ñ Testando tempo de carregamento do modelo...")
        
        start_time = time.time()
        llm = self.model_manager.get_llm('mistral-7b-gguf')
        load_time = time.time() - start_time
        
        print(f"‚è±Ô∏è Tempo de carregamento: {load_time:.2f} segundos")
        
        # Verificar se o modelo carregou corretamente
        self.assertIsNotNone(llm, "Modelo deve carregar sem erros")
        
        # Tempo deve ser razo√°vel (menos de 10 segundos para carregamento inicial)
        self.assertLess(load_time, 10.0, f"Tempo de carregamento muito alto: {load_time:.2f}s")
        
        print("‚úÖ Teste de carregamento do modelo passou!")
    
    def test_chat_response_time(self):
        """Testa tempo de resposta do chat"""
        print("\nüí¨ Testando tempo de resposta do chat...")
        
        # Criar relat√≥rio de exemplo
        from src.models.schemas import RelatorioFiscal, ResultadoAnalise, NivelRisco
        from datetime import datetime
        
        resultado = ResultadoAnalise(
            chave_acesso="12345678901234567890123456789012345678901234",
            score_risco_geral=25,
            nivel_risco=NivelRisco.BAIXO,
            fraudes_detectadas=[],
            itens_suspeitos=[],
            acoes_recomendadas=[],
            timestamp_analise=datetime.now(),
            tempo_processamento_segundos=2.5
        )
        
        relatorio = RelatorioFiscal(
            resultado_analise=resultado,
            resumo_executivo="NF-e analisada com sucesso",
            detalhes_tecnicos="An√°lise completa realizada",
            recomendacoes="Aprovar NF-e"
        )
        
        # Carregar relat√≥rio no agente
        self.agente5.carregar_relatorio(relatorio)
        
        # Testar m√∫ltiplas perguntas
        perguntas_teste = [
            "Qual √© o score de risco desta NF-e?",
            "Existem fraudes detectadas?",
            "Posso aprovar esta NF-e?",
            "Explique o resultado da an√°lise"
        ]
        
        tempos_resposta = []
        
        for pergunta in perguntas_teste:
            start_time = time.time()
            resposta = self.agente5.conversar(pergunta)
            response_time = time.time() - start_time
            
            tempos_resposta.append(response_time)
            print(f"  üìù Pergunta: {pergunta[:30]}...")
            print(f"  ‚è±Ô∏è Tempo: {response_time:.2f}s")
            print(f"  üìÑ Resposta: {resposta[:50]}...")
            
            # Verificar se a resposta n√£o est√° vazia
            self.assertIsNotNone(resposta, "Resposta n√£o deve ser None")
            self.assertGreater(len(resposta), 0, "Resposta n√£o deve estar vazia")
        
        # Calcular tempo m√©dio
        tempo_medio = sum(tempos_resposta) / len(tempos_resposta)
        print(f"\nüìä Tempo m√©dio de resposta: {tempo_medio:.2f} segundos")
        
        # Verificar se atende √† meta (< 3 segundos)
        self.assertLess(tempo_medio, 3.0, f"Tempo m√©dio de resposta muito alto: {tempo_medio:.2f}s")
        
        print("‚úÖ Teste de tempo de resposta do chat passou!")
    
    def test_nfe_processing_time(self):
        """Testa tempo de processamento de NF-e"""
        print("\nüìÑ Testando tempo de processamento de NF-e...")
        
        # Criar NF-e de exemplo
        nfe = NFe(
            chave_acesso="12345678901234567890123456789012345678901234",
            numero="12345",
            serie="1",
            data_emissao=datetime.now(),
            cnpj_emitente="12345678000195",
            razao_social_emitente="Empresa Exemplo LTDA",
            cnpj_destinatario="98765432000123",
            razao_social_destinatario="Cliente Exemplo LTDA",
            valor_total=1000.00,
            valor_produtos=1000.00,
            itens=[
                ItemNFe(
                    numero_item=1,
                    descricao="Produto de exemplo para teste",
                    ncm_declarado="12345678",
                    quantidade=1,
                    valor_unitario=1000.00
                ),
                ItemNFe(
                    numero_item=2,
                    descricao="Outro produto de exemplo",
                    ncm_declarado="87654321",
                    quantidade=2,
                    valor_unitario=500.00
                )
            ]
        )
        
        # Testar processamento completo
        start_time = time.time()
        
        # Simular classifica√ß√£o NCM
        classificacoes = {}
        for item in nfe.itens:
            classificacoes[item.numero_item] = {
                "ncm_predito": item.ncm_declarado,
                "confianca": 0.95
            }
        
        # Executar an√°lise
        resultado = self.orquestrador.analisar_nfe(nfe, classificacoes)
        
        processing_time = time.time() - start_time
        
        print(f"‚è±Ô∏è Tempo de processamento: {processing_time:.2f} segundos")
        print(f"üìä Score de risco: {resultado.score_risco_geral}")
        print(f"üîç Fraudes detectadas: {len(resultado.fraudes_detectadas)}")
        
        # Verificar se atende √† meta (< 10 segundos)
        self.assertLess(processing_time, 10.0, f"Tempo de processamento muito alto: {processing_time:.2f}s")
        
        # Verificar se o resultado foi gerado
        self.assertIsNotNone(resultado, "Resultado da an√°lise deve ser gerado")
        self.assertIsNotNone(resultado.score_risco_geral, "Score de risco deve ser calculado")
        
        print("‚úÖ Teste de tempo de processamento de NF-e passou!")
    
    def test_cache_performance(self):
        """Testa performance do cache do chat"""
        print("\nüíæ Testando performance do cache...")
        
        # Criar relat√≥rio de exemplo
        from src.models.schemas import RelatorioFiscal, ResultadoAnalise, NivelRisco
        from datetime import datetime
        
        resultado = ResultadoAnalise(
            chave_acesso="12345678901234567890123456789012345678901234",
            score_risco_geral=25,
            nivel_risco=NivelRisco.BAIXO,
            fraudes_detectadas=[],
            itens_suspeitos=[],
            acoes_recomendadas=[],
            timestamp_analise=datetime.now(),
            tempo_processamento_segundos=2.5
        )
        
        relatorio = RelatorioFiscal(
            resultado_analise=resultado,
            resumo_executivo="NF-e analisada com sucesso",
            detalhes_tecnicos="An√°lise completa realizada",
            recomendacoes="Aprovar NF-e"
        )
        
        self.agente5.carregar_relatorio(relatorio)
        
        # Primeira pergunta (sem cache)
        pergunta = "Qual √© o score de risco desta NF-e?"
        
        start_time = time.time()
        resposta1 = self.agente5.conversar(pergunta)
        tempo_sem_cache = time.time() - start_time
        
        # Segunda pergunta (com cache)
        start_time = time.time()
        resposta2 = self.agente5.conversar(pergunta)
        tempo_com_cache = time.time() - start_time
        
        print(f"‚è±Ô∏è Tempo sem cache: {tempo_sem_cache:.2f}s")
        print(f"‚è±Ô∏è Tempo com cache: {tempo_com_cache:.2f}s")
        print(f"üìà Melhoria: {((tempo_sem_cache - tempo_com_cache) / tempo_sem_cache * 100):.1f}%")
        
        # Verificar se as respostas s√£o iguais
        self.assertEqual(resposta1, resposta2, "Respostas com e sem cache devem ser iguais")
        
        # Verificar se o cache melhorou a performance
        self.assertLess(tempo_com_cache, tempo_sem_cache, "Cache deve melhorar a performance")
        
        # Verificar estat√≠sticas do cache
        stats = self.agente5.obter_estatisticas_cache()
        print(f"üìä Estat√≠sticas do cache: {stats}")
        
        self.assertGreater(stats['total_entradas'], 0, "Cache deve ter entradas")
        
        print("‚úÖ Teste de performance do cache passou!")
    
    def test_validation_dataset_performance(self):
        """Testa performance do dataset de valida√ß√£o"""
        print("\nüìä Testando performance do dataset de valida√ß√£o...")
        
        # Criar dados de exemplo
        nfe = NFe(
            chave_acesso="12345678901234567890123456789012345678901234",
            numero="12345",
            serie="1",
            data_emissao=datetime.now(),
            cnpj_emitente="12345678000195",
            razao_social_emitente="Empresa Exemplo LTDA",
            cnpj_destinatario="98765432000123",
            razao_social_destinatario="Cliente Exemplo LTDA",
            valor_total=1000.00,
            valor_produtos=1000.00,
            itens=[
                ItemNFe(
                    numero_item=1,
                    descricao="Produto de exemplo",
                    ncm_declarado="12345678",
                    quantidade=1,
                    valor_unitario=1000.00
                )
            ]
        )
        
        # Testar adi√ß√£o de amostra
        start_time = time.time()
        
        self.validation_dataset.add_nfe_sample(
            nfe=nfe,
            expected_classifications={1: "12345678"},
            expected_frauds=[],
            processing_time=2.5
        )
        
        add_time = time.time() - start_time
        
        # Testar c√°lculo de m√©tricas
        start_time = time.time()
        metrics = self.validation_dataset.calculate_accuracy_metrics()
        metrics_time = time.time() - start_time
        
        print(f"‚è±Ô∏è Tempo para adicionar amostra: {add_time:.3f}s")
        print(f"‚è±Ô∏è Tempo para calcular m√©tricas: {metrics_time:.3f}s")
        print(f"üìä M√©tricas calculadas: {metrics}")
        
        # Verificar se as opera√ß√µes s√£o r√°pidas
        self.assertLess(add_time, 1.0, "Adi√ß√£o de amostra deve ser r√°pida")
        self.assertLess(metrics_time, 1.0, "C√°lculo de m√©tricas deve ser r√°pido")
        
        # Verificar se as m√©tricas foram calculadas
        self.assertIsInstance(metrics, dict, "M√©tricas devem ser um dicion√°rio")
        self.assertIn('ncm_accuracy', metrics, "M√©tricas devem incluir acur√°cia NCM")
        
        print("‚úÖ Teste de performance do dataset de valida√ß√£o passou!")
    
    def test_metrics_dashboard_performance(self):
        """Testa performance do dashboard de m√©tricas"""
        print("\nüìà Testando performance do dashboard de m√©tricas...")
        
        # Adicionar alguns pontos de m√©trica
        start_time = time.time()
        
        for i in range(10):
            self.metrics_dashboard.add_metric_point(
                processing_time=2.0 + i * 0.1,
                num_items=3 + i,
                score_risco=20 + i * 5,
                frauds_detected=i % 2
            )
        
        add_time = time.time() - start_time
        
        # Testar c√°lculo de m√©tricas atuais
        start_time = time.time()
        current_metrics = self.metrics_dashboard._calculate_current_metrics()
        calc_time = time.time() - start_time
        
        print(f"‚è±Ô∏è Tempo para adicionar 10 pontos: {add_time:.3f}s")
        print(f"‚è±Ô∏è Tempo para calcular m√©tricas: {calc_time:.3f}s")
        print(f"üìä M√©tricas atuais: {current_metrics}")
        
        # Verificar se as opera√ß√µes s√£o r√°pidas
        self.assertLess(add_time, 1.0, "Adi√ß√£o de pontos deve ser r√°pida")
        self.assertLess(calc_time, 1.0, "C√°lculo de m√©tricas deve ser r√°pido")
        
        # Verificar se as m√©tricas foram calculadas
        self.assertIsInstance(current_metrics, dict, "M√©tricas devem ser um dicion√°rio")
        self.assertIn('avg_processing_time', current_metrics, "M√©tricas devem incluir tempo m√©dio")
        
        print("‚úÖ Teste de performance do dashboard de m√©tricas passou!")
    
    def test_system_availability(self):
        """Testa disponibilidade do sistema"""
        print("\nüîÑ Testando disponibilidade do sistema...")
        
        # Testar inicializa√ß√£o de todos os componentes
        components = [
            ("Model Manager", self.model_manager),
            ("Agente 1", self.agente1),
            ("Agente 2", self.agente2),
            ("Agente 3", self.agente3),
            ("Agente 5", self.agente5),
            ("Orquestrador", self.orquestrador),
            ("Dataset de Valida√ß√£o", self.validation_dataset),
            ("Dashboard de M√©tricas", self.metrics_dashboard)
        ]
        
        for name, component in components:
            self.assertIsNotNone(component, f"{name} deve estar dispon√≠vel")
            print(f"  ‚úÖ {name}: Operacional")
        
        # Testar opera√ß√µes b√°sicas
        try:
            # Testar LLM
            response = self.llm.invoke("Teste de disponibilidade")
            self.assertIsNotNone(response, "LLM deve responder")
            
            # Testar dataset
            metrics = self.validation_dataset.calculate_accuracy_metrics()
            self.assertIsInstance(metrics, dict, "Dataset deve funcionar")
            
            # Testar dashboard
            current_metrics = self.metrics_dashboard._calculate_current_metrics()
            self.assertIsInstance(current_metrics, dict, "Dashboard deve funcionar")
            
        except Exception as e:
            self.fail(f"Sistema deve estar dispon√≠vel, mas falhou: {e}")
        
        print("‚úÖ Teste de disponibilidade do sistema passou!")
    
    def run_performance_report(self):
        """Gera relat√≥rio de performance"""
        print("\nüìä GERANDO RELAT√ìRIO DE PERFORMANCE")
        print("=" * 50)
        
        # Executar todos os testes
        test_methods = [
            self.test_model_loading_time,
            self.test_chat_response_time,
            self.test_nfe_processing_time,
            self.test_cache_performance,
            self.test_validation_dataset_performance,
            self.test_metrics_dashboard_performance,
            self.test_system_availability
        ]
        
        results = {}
        
        for test_method in test_methods:
            try:
                test_method()
                results[test_method.__name__] = "‚úÖ PASSOU"
            except Exception as e:
                results[test_method.__name__] = f"‚ùå FALHOU: {e}"
        
        # Exibir resultados
        print("\nüìã RESULTADOS DOS TESTES:")
        for test_name, result in results.items():
            print(f"  {test_name}: {result}")
        
        # Calcular score geral
        passed = sum(1 for result in results.values() if result.startswith("‚úÖ"))
        total = len(results)
        score = (passed / total) * 100
        
        print(f"\nüéØ SCORE GERAL: {score:.1f}% ({passed}/{total} testes passaram)")
        
        if score >= 90:
            print("üèÜ EXCELENTE! Sistema atende √†s m√©tricas de performance.")
        elif score >= 70:
            print("üëç BOM! Sistema atende √† maioria das m√©tricas.")
        else:
            print("‚ö†Ô∏è ATEN√á√ÉO! Sistema precisa de melhorias.")
        
        return results


def run_performance_tests():
    """
    Fun√ß√£o principal para executar testes de performance
    """
    print("üöÄ FISCALAI MVP - TESTES DE PERFORMANCE")
    print("=" * 50)
    
    # Criar suite de testes
    suite = unittest.TestSuite()
    
    # Adicionar testes
    test_suite = PerformanceTestSuite()
    suite.addTest(test_suite)
    
    # Executar relat√≥rio
    results = test_suite.run_performance_report()
    
    return results


if __name__ == "__main__":
    run_performance_tests()
